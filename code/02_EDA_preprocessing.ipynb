{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d492fa-07b0-4837-8727-b9a3ab80f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed430b6-e425-4ce1-9d1f-716cd55596e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df_geo_comm_00 = pd.read_csv('../data/raw/df_geo_comm_00.csv')\n",
    "df_geo_comm_01 = pd.read_csv('../data/raw/df_geo_comm_01.csv')\n",
    "\n",
    "df_geo_subm_00 = pd.read_csv('../data/raw/df_geo_subm_00.csv')\n",
    "df_geo_subm_01 = pd.read_csv('../data/raw/df_geo_subm_01.csv')\n",
    "\n",
    "df_wor_comm_00 = pd.read_csv('../data/raw/df_wor_comm_00.csv')\n",
    "df_wor_comm_01 = pd.read_csv('../data/raw/df_wor_comm_01.csv')\n",
    "\n",
    "df_wor_subm_00 = pd.read_csv('../data/raw/df_wor_subm_00.csv')\n",
    "df_wor_subm_01 = pd.read_csv('../data/raw/df_wor_subm_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea183c3-44e0-4693-a06f-1ca982dc0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_comm = pd.concat([df_geo_comm_00, df_geo_comm_01], axis = 0, ignore_index = True)\n",
    "\n",
    "df_geo_subm = pd.concat([df_geo_subm_00, df_geo_subm_01], axis = 0, ignore_index = True)\n",
    "\n",
    "df_wor_comm = pd.concat([df_wor_comm_00, df_wor_comm_01], axis = 0, ignore_index = True)\n",
    "\n",
    "df_wor_subm = pd.concat([df_wor_subm_00, df_wor_subm_01], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0750fdc4-7b4b-47c7-9165-8b9009292c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier column, positive indicates is r/worldnews\n",
    "df_geo_subm['is_news'] = 0\n",
    "df_wor_subm['is_news'] = 1\n",
    "\n",
    "# comments\n",
    "df_geo_comm['is_news'] = 0\n",
    "df_wor_comm['is_news'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd5a4a4-bfb5-430d-9cd6-7bc8cc727d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat both subm columns\n",
    "df_all_subm = pd.concat([df_geo_subm[['title', 'is_news']], df_wor_subm[['title', 'is_news']]], axis = 0, ignore_index = True)\n",
    "df_all_comm = pd.concat([df_geo_comm[['body', 'is_news']], df_wor_comm[['body', 'is_news']]], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75869d4-4411-4a83-be98-db1a16321191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows with value '[removed]'\n",
    "# [removed] indicates that post was removed from subreddit as rules violation\n",
    "df_all_comm.drop(df_all_comm[df_all_comm['body'] == '[removed]'].index, inplace = True)\n",
    "\n",
    "df_all_comm.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4d9e7b-87a4-4d01-9876-b29ffce43127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove linebreaks from comments, and replace digits\n",
    "for i in range(len(df_all_comm['body'])):\n",
    "    df_all_comm.loc[i, 'body'] = df_all_comm.loc[i, 'body'].replace('\\n', ' ')\n",
    "    df_all_comm.loc[i, 'body'] = re.sub('\\d', ' @ ', df_all_comm.loc[i, 'body'])\n",
    "    \n",
    "for i in range(len(df_all_subm['title'])):\n",
    "    df_all_subm.loc[i,'title'] = re.sub('\\d', ' @ ', df_all_subm.loc[i,'title'])\n",
    "    \n",
    "    #chaining operations can result in copy warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a3ae1e-9dad-4d9f-95e2-25b7f322f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to drop rows below non-ascii:len(string) ratio threshold of 4.5%\n",
    "    # will drop non-english postings and bot-generated advertisements that have heavy use of emojis\n",
    "\n",
    "def non_ascii_dropper(dataframe, column, threshold_ratio):\n",
    "    '''\n",
    "    Identifies non-ascii characters in dataframe[column], replaces non-ascii characters withan\n",
    "    underscore in a view, and drops the value if the ratio of non-ascii : ascii characters is above\n",
    "    treshold_ratio.\n",
    "    Helpful in removing non-English postings or emoji-laden posts, which are signs of bot-generated\n",
    "    advertisements.\n",
    "    '''\n",
    "    for i in range(len(dataframe[column])):\n",
    "        for char in range(len(dataframe[column][i])):\n",
    "            if dataframe[column][i][char].isascii() == False:\n",
    "                non_ascii = dataframe[column][i][char]\n",
    "                dataframe.loc[i, column] = dataframe[column][i].replace(non_ascii, '_')\n",
    "    for i in range(len(dataframe[column])):\n",
    "        measure = len(dataframe[column][i])\n",
    "        count = 0\n",
    "        for char in dataframe[column][i]:\n",
    "            if char == '_':\n",
    "                count += 1\n",
    "        if count/measure >= threshold_ratio:\n",
    "            dataframe.drop([i], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129c8be9-c7ac-4288-b8be-96e4d117b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ascii_dropper(df_all_subm, 'title', 0.06)\n",
    "non_ascii_dropper(df_all_comm, 'body', 0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54940f5-239f-4b66-b520-b8803c2c05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any ascii typecast by non_ascii_dropper\n",
    "# prevents our model from learning on non-ascii\n",
    "\n",
    "df_all_subm['title'] = df_all_subm['title'].map(lambda i: i.replace('_', ''))\n",
    "df_all_comm['body'] = df_all_comm['body'].map(lambda i: i.replace('_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1e79bd-2bdb-4c90-b3a1-2afac06b6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indexes\n",
    "df_all_subm.reset_index(drop = True, inplace = True)\n",
    "df_all_comm.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056fa5c6-08bd-41b4-9b60-4d8a9db01ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sentiment intensity scores column\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_all_subm['compound_si'] = [sid.polarity_scores(df_all_subm['title'][i])['compound'] for i in range(len(df_all_subm['title']))]\n",
    "df_all_comm['compound_si'] = [sid.polarity_scores(df_all_comm['body'][i])['compound'] for i in range(len(df_all_comm['body']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de4691fb-a61f-4405-b052-9fe18fd9191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "df_all_subm.to_csv('../data/df_all_subm.csv', index = False)\n",
    "df_all_comm.to_csv('../data/df_all_comm.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de136b6-e74a-426a-b404-f9a666ffcf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and export single .csv with all text\n",
    "df_all = pd.concat([df_all_subm.rename(columns = {'title' :'text'}), df_all_comm.rename(columns = {'body' :'text'})], ignore_index = True)\n",
    "df_all.to_csv('../data/df_all_text.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b75afd-1b8c-4db7-a267-78207c431927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
